from process_ocean_data.tools import google, hakai, process

from seabird.cnv import fCNV
from seabird.netcdf import cnv2nc

from ioos_qc.config import NcQcConfig

import xarray as xr
import netCDF4

import json
from os import path


def get_hakai_ctd_log(dest_dir='.'):
    # Hakai CTD Deployment log
    INSTRUMENT_LOG_LINK = \
        "https://docs.google.com/spreadsheets/d/1lkI250zOMJIQ0Z3802QbJHM-dF-zqNxc16AcwxaYCM8/edit?usp=sharing"

    # Get Hakai Instrument Log and convert it to a dataframe
    df = google.get_from_google_public(INSTRUMENT_LOG_LINK)

    # Apply transformations to Hakai log
    #  - Convert times to datetime objects in UTC
    #  - Retrieve instrument time offset from UTC
    #  - Convert lat/long to decimal degrees
    #  - Compute trilateration if available
    #  - Generate standard Hakai File Name
    df = hakai.transform_hakai_log(df, dest_dir)
    return df


def download_raw_data(df, dest_dir='.'):
    # Download Raw Data From link and add path to instrument log
    df['raw_file_path'] = ''
    for index, row in df.iterrows():
        df.loc[index, 'raw_file_path'] = path.join(dest_dir, row['file_name']+'.cnv')
        google.get_from_google_public(
            row['Link to Raw Data'],
            df.loc[index, 'raw_file_path']
        )
    return df


def process_data(row, dest_dir='.'):
    """ Apply standard processing method and QAQC to the CTD time series."""
    if row['Link to Raw Data'] is None:
        return

    file_output = dest_dir + row['file_name']
    # Read Seabird CNV
    print('Read '+row['raw_file_path'])
    c = fCNV(row['raw_file_path'])

    # Save to NetCDF
    print('Save to '+row['file_name']+'_L0.nc')
    l0_file = path.join(dest_dir, row['file_name']+'_L0.nc')
    l1_file = path.join(dest_dir, row['file_name'] + '_L1.nc')
    cnv2nc(c, l0_file)

    # Add Metadata to NetCDF
    #  + Metadata Variables
    #  + Global Attributes
    nc = netCDF4.Dataset(l0_file, 'a')

    # Latitude
    latitude = nc.createVariable('latitude', float)
    latitude.units = 'degrees_north'
    latitude[:] = row['Latitude']

    # Longitude
    longitude = nc.createVariable('longitude', float)
    longitude.units = 'degrees_east'
    longitude[:] = row['Longitude']

    # Station
    station = nc.createVariable('station', str)
    station[0] = row['Site']

    # File name (timeseries_id)
    # TODO this is temporary I would prefer having access to the instrument serial number instead
    file_name = nc.createVariable('file_id', str)
    file_name[0] = row['file_name']

    # TODO Add timeseries_id and cdm_data_type info but it may be better to rely on the
    #  seabird tool for doing that
    # timeseries_id Can be generated by the tool itself

    # Add extra metadata as global attributes
    for key, value in row.drop(['Latitude', 'Longitude']).items():
        if value:
            if type(value) is not (float, int, str):
                value = str(value)  # Likely datetime

            nc.setncattr(key.split('(')[0].strip(), value)  # Keep anything before (

    # Find Crop data to keep in water only
    ds = xr.open_dataset(l0_file)
    start_end_results = process.detect_start_end(ds, 'time', 'PRESPR01',
                                                 figure_path=file_output + '_crop.png')

    # Output Cropped time series a L1
    ds.loc[dict(time=slice(start_end_results['first_good_record_time'],
                           start_end_results['last_good_record_time']))]\
        .to_netcdf(l1_file)

    # Run QARTOD on the NetCDF file
    # Retrieve Hakai QARTOD Tests
    ctd_qc_config = path.join(path.dirname(__file__), 'qc_config/seabird_ctd_time_series.json')
    with open(ctd_qc_config) as f:
        config = json.load(f)

    qc = NcQcConfig(config, tinp='time')
    qartod_results = qc.run(l1_file)

    # Upload QARTOD Flags to NetCDF
    qc.save_to_netcdf(l1_file, qartod_results)
