from process_ocean_data.tools import google, hakai, process

from seabird.cnv import fCNV
from seabird.netcdf import cnv2nc

from ioos_qc.config import NcQcConfig

import xarray as xr
import netCDF4

import json
from os import path

# File path
# dest_dir = r"/mnt/d/hakai_CTD/"
dest_dir = r"E:/hakai_CTD/"

# Define Spreadsheet ID
# Hakai CTD Deployment log
INSTRUMENT_LOG_LINK = "https://docs.google.com/spreadsheets/d/1lkI250zOMJIQ0Z3802QbJHM-dF-zqNxc16AcwxaYCM8/edit?usp=sharing"

# Get Hakai ADCP Log data and convert it to a dataframe
df = google.get_from_google_public(INSTRUMENT_LOG_LINK)

# Apply transformations to Hakai log
#  - Convert times to datetime objects in UTC
#  - Retrieve instrument time offset from UTC
#  - Convert lat/long to decimal degrees
#  - Compute trilateration if available
#  - Generate standard Hakai File Name
df = hakai.transform_hakai_log(df, dest_dir)

# Download CTD data
# Create a dictionary with the output file name as key and link to the data as value
ctd_files = {row['file_name']+'.cnv': row['Link to Raw Data'] for index, row in df.iterrows()}
for file, link in ctd_files.items():
    google.get_from_google_public(link, path.join(dest_dir, file))

# Loop through each files
for index, row in df.iterrows():
    if row['Link to Raw Data']:
        file_output = dest_dir + row['file_name']
        # Read Seabird CNV
        print('Read '+row['file_name']+'.cnv')
        c = fCNV(file_output+'.cnv')

        # Save to NetCDF
        print('Save to '+row['file_name']+'_L0.nc')
        cnv2nc(c, file_output+'_L0.nc')

        # Add Metadata to NetCDF
        #  + Metadata Variables
        #  + Global Attributes
        nc = netCDF4.Dataset(file_output + '_L0.nc', 'a')

        # Latitude
        latitude = nc.createVariable('latitude', float)
        latitude.units = 'degrees_north'
        latitude[:] = row['Latitude']

        # Longitude
        longitude = nc.createVariable('longitude', float)
        longitude.units = 'degrees_east'
        longitude[:] = row['Longitude']

        # Station
        station = nc.createVariable('station', str)
        station[0] = row['Site']

        # File name (timeseries_id)
        # TODO this is temporary I would prefer having access to the instrument serial number instead
        file_name = nc.createVariable('file_id', str)
        file_name[0] = row['file_name']

        # TODO Add timeseries_id and cdm_data_type info but it may be better to rely on the
        #  seabird tool for doing that
        # timeseries_id Can be generated by the tool itself

        # Add extra metadata as global attributes
        for key, value in row.drop(['Latitude', 'Longitude']).items():
            if value:
                if type(value) is not (float, int, str):
                    value = str(value)  # Likely datetime

                nc.setncattr(key.split('(')[0].strip(), value)  # Keep anything before (

        # Find Crop data to keep in water only
        ds = xr.open_dataset(file_output+'_L0.nc')
        start_end_results = process.detect_start_end(ds, 'time', 'PRESPR01',
                                                     figure_path=file_output + '_crop.png')

        # Output Cropped time series a L1
        ds.loc[dict(time=slice(start_end_results['first_good_record_time'],
                               start_end_results['last_good_record_time']))]\
            .to_netcdf(file_output+'_L1.nc')

        # Run QARTOD on the NetCDF file
        # Retrieve Hakai QARTOD Tests
        ctd_qc_config = path.join(path.dirname(__file__), 'qc_config/seabird_ctd_time_series.json')
        with open(ctd_qc_config) as f:
            config = json.load(f)

        qc = NcQcConfig(config, tinp='time')
        qartod_results = qc.run(file_output + '_L1.nc')

        # Upload QARTOD Flags to NetCDF
        qc.save_to_netcdf(file_output + '_L1.nc', qartod_results)

print('works!')
