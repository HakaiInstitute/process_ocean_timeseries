import google
import hakai
import process

from seabird.cnv import fCNV
from seabird.netcdf import cnv2nc

from ioos_qc import qartod
from ioos_qc.config import NcQcConfig

import xarray as xr
import netCDF4
import re

# File path
# dest_dir = r"/mnt/d/hakai_CTD/"
dest_dir = r"D:/hakai_CTD/"

# Define Spreadsheet ID
# Hakai ADCP Deployment log
# The ID and range of a sample spreadsheet.
SAMPLE_SPREADSHEET_ID = '1lkI250zOMJIQ0Z3802QbJHM-dF-zqNxc16AcwxaYCM8'
SAMPLE_RANGE_NAME = 'CTD_log!A:AN'

# Get Hakai ADCP Log data and convert it to a dataframe
val = google.get_google_sheet(SAMPLE_SPREADSHEET_ID, SAMPLE_RANGE_NAME)
df = google.convert_google_sheet_to_dataframe(val)

# Apply transformations to Hakai log
#  - Convert times to datetime objects in UTC
#  - Retrieve instrument time offset from UTC
#  - Convert lat/long to decimal degrees
#  - Compute trilateration if available
#  - Generate standard Hakai File Name
df = hakai.transform_hakai_log(df, dest_dir)

# Download CTD data
# Create a dictionary with the output file name as key and link to the data as value
ctd_files = {row['file_name']+'.cnv': row['Link to Raw Data'] for index, row in df.iterrows()}
hakai.download_file(ctd_files, dest_dir)

# Loop through each files
for index, row in df.iterrows():
    if row['Link to Raw Data']:
        file_output = dest_dir + row['file_name']
        # Read Seabird CNV
        print('Read '+row['file_name']+'.cnv')
        c = fCNV(file_output+'.cnv')

        # Save to NetCDF
        print('Save to '+row['file_name']+'.nc')
        cnv2nc(c, file_output+'.nc')

        # Add Metadata to NetCDF
        #  + Metadata Variables
        #  + Global Attributes
        nc = netCDF4.Dataset(file_output + '.nc', 'a')

        # Latitude
        latitude = nc.createVariable('latitude', float)
        latitude.units = 'degrees North'
        latitude[:] = row['Latitude']

        # Longitude
        longitude = nc.createVariable('longitude', float)
        longitude.units = 'degrees East'
        longitude[:] = row['Longitude']

        # Station
        station = nc.createVariable('station', str)
        station[0] = row['Site']

        # TODO Add timeseries_id and cdm_data_type info but it may be better to rely on the seabird tool for doing that
        # timeseries_id Can be generated by the tool itself

        # Add extra metadata as global attributes
        for key, value in row.drop(['Latitude', 'Longitude']).items():
            if value:
                if type(value) is not (float, int, str):
                    value = str(value)  # Likely datetime

                nc.setncattr(key.split('(')[0].strip(), value)  # Keep anything before (

        # Find Crop data to keep in water only
        ds = xr.open_dataset(file_output+'.nc')
        start_end_results = process.detect_start_end(ds,
                                                     'time', 'PRESPR01',
                                                     time_dim='time',
                                                     figure_path=file_output+'_crop.png')

        # Output Cropped time series a L1
        ds.loc[dict(time=slice(start_end_results['first_good_record_time'],
                               start_end_results['last_good_record_time']))]\
            .to_netcdf(file_output+'_L1.nc')

        # Run QARTOD on the NetCDF file
        # Retrieve Hakai QARTOD Tests
        qc = NcQcConfig(config)
        qartod_results = qc.run(file_output + '.nc')
        qc.save_to_netcdf(file_output+ '.nc', qartod_results)

print('works!')
